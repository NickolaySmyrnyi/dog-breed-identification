{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRsJninIz10W",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KQJ7iAu0UAy"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qepSozIC3jpt"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRZHIav93_Aw"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ264-E24zGB",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "! kaggle competitions download -c dog-breed-identification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkCm2zJp5NNu",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "! unzip dog-breed-identification.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ykTQBZ_baPcl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5JBJhic3ORG",
        "outputId": "d162f838-7782-4776-f352-8dca24048020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8178 validated image filenames belonging to 120 classes.\n",
            "Found 2044 validated image filenames belonging to 120 classes.\n"
          ]
        }
      ],
      "source": [
        "base_dir = 'train'\n",
        "img_size = (400, 400)\n",
        "batch_size = 32\n",
        "\n",
        "labels = pd.read_csv('labels.csv')\n",
        "labels['id'] = labels['id'].apply(lambda x: x +'.jpg')\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=20,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest',\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=labels,\n",
        "                                                    directory=base_dir,\n",
        "                                                    x_col='id',\n",
        "                                                    y_col='breed',\n",
        "                                                    target_size=img_size,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_dataframe(dataframe=labels,\n",
        "                                                         directory=base_dir,\n",
        "                                                         x_col='id',\n",
        "                                                         y_col='breed',\n",
        "                                                         target_size=img_size,\n",
        "                                                         batch_size=batch_size,\n",
        "                                                         class_mode='categorical',\n",
        "                                                         subset='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8x11w9gmWLg",
        "outputId": "231fd56f-c58f-4413-92f5-fefb49314b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219055592/219055592 [==============================] - 6s 0us/step\n",
            "Epoch 1/10\n",
            "256/256 [==============================] - 628s 2s/step - loss: 1.6297 - accuracy: 0.7838 - val_loss: 0.4502 - val_accuracy: 0.9139\n",
            "Epoch 2/10\n",
            "256/256 [==============================] - 568s 2s/step - loss: 0.3460 - accuracy: 0.9149 - val_loss: 0.3296 - val_accuracy: 0.9159\n",
            "Epoch 3/10\n",
            "256/256 [==============================] - 544s 2s/step - loss: 0.2734 - accuracy: 0.9228 - val_loss: 0.3043 - val_accuracy: 0.9119\n",
            "Epoch 4/10\n",
            "256/256 [==============================] - 531s 2s/step - loss: 0.2446 - accuracy: 0.9270 - val_loss: 0.2812 - val_accuracy: 0.9198\n",
            "Epoch 5/10\n",
            "256/256 [==============================] - 575s 2s/step - loss: 0.2231 - accuracy: 0.9290 - val_loss: 0.2892 - val_accuracy: 0.9159\n",
            "Epoch 6/10\n",
            "256/256 [==============================] - 547s 2s/step - loss: 0.2113 - accuracy: 0.9318 - val_loss: 0.2633 - val_accuracy: 0.9227\n",
            "Epoch 7/10\n",
            "256/256 [==============================] - 600s 2s/step - loss: 0.1939 - accuracy: 0.9370 - val_loss: 0.3108 - val_accuracy: 0.9031\n",
            "Epoch 8/10\n",
            "256/256 [==============================] - 574s 2s/step - loss: 0.1953 - accuracy: 0.9349 - val_loss: 0.2755 - val_accuracy: 0.9203\n",
            "Epoch 9/10\n",
            "256/256 [==============================] - 579s 2s/step - loss: 0.1805 - accuracy: 0.9407 - val_loss: 0.2883 - val_accuracy: 0.9080\n"
          ]
        }
      ],
      "source": [
        "def setup_inceptionresnetv2_model(num_classes):\n",
        "    base_model = InceptionResNetV2(weights='imagenet', include_top=False)\n",
        "    x = base_model.output\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model_inceptionresnetv2 = setup_inceptionresnetv2_model(len(train_generator.class_indices))\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model_inceptionresnetv2.fit(train_generator, validation_data=validation_generator, epochs=10, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_inceptionv3_model(num_classes):\n",
        "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "    x = base_model.output\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model_inceptionv3 = setup_inceptionv3_model(len(train_generator.class_indices))\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model_inceptionv3.fit(train_generator, validation_data=validation_generator, epochs=10, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1pUySybEqgH",
        "outputId": "191646ed-a53b-4730-9010-1a8b6265ff17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 5s 0us/step\n",
            "Epoch 1/10\n",
            "256/256 [==============================] - 496s 2s/step - loss: 1.8271 - accuracy: 0.7011 - val_loss: 0.6329 - val_accuracy: 0.8591\n",
            "Epoch 2/10\n",
            "256/256 [==============================] - 464s 2s/step - loss: 0.4537 - accuracy: 0.8935 - val_loss: 0.4250 - val_accuracy: 0.8870\n",
            "Epoch 3/10\n",
            "256/256 [==============================] - 473s 2s/step - loss: 0.3304 - accuracy: 0.9137 - val_loss: 0.3760 - val_accuracy: 0.8855\n",
            "Epoch 4/10\n",
            "256/256 [==============================] - 468s 2s/step - loss: 0.2847 - accuracy: 0.9170 - val_loss: 0.3864 - val_accuracy: 0.8787\n",
            "Epoch 5/10\n",
            "256/256 [==============================] - 470s 2s/step - loss: 0.2548 - accuracy: 0.9230 - val_loss: 0.3374 - val_accuracy: 0.8977\n",
            "Epoch 6/10\n",
            "256/256 [==============================] - 467s 2s/step - loss: 0.2254 - accuracy: 0.9299 - val_loss: 0.3474 - val_accuracy: 0.8924\n",
            "Epoch 7/10\n",
            "256/256 [==============================] - 473s 2s/step - loss: 0.2115 - accuracy: 0.9353 - val_loss: 0.3432 - val_accuracy: 0.8904\n",
            "Epoch 8/10\n",
            "256/256 [==============================] - 477s 2s/step - loss: 0.1866 - accuracy: 0.9424 - val_loss: 0.3624 - val_accuracy: 0.8850\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}